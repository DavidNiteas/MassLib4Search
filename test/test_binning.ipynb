{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a504832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dask.bag as db\n",
    "from torch.nested import nested_tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from typing import Literal,List,Optional,Tuple,Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d2897b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_device(\n",
    "    device: Union[str, torch.device, Literal['auto']], \n",
    "    default: torch.device\n",
    ") -> torch.device:\n",
    "    if isinstance(device, torch.device):\n",
    "        return device\n",
    "    if device == 'auto':\n",
    "        return default\n",
    "    if device == 'cuda':\n",
    "        device = 'cuda:0'\n",
    "    return torch.device(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_bin_cells(\n",
    "    min_mz: float = 50.0,\n",
    "    max_mz: float = 1000.0,\n",
    "    bin_size: float = 1,\n",
    "    device: torch.device = torch.device('cpu'),\n",
    ") -> torch.Tensor: # [num_bins, 2 (start, end)]\n",
    "    \n",
    "    starts = torch.arange(start=min_mz, end=max_mz, step=bin_size, device=device)\n",
    "    \n",
    "    ends = starts + bin_size\n",
    "    \n",
    "    return torch.stack((starts, ends), dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def binning_step(\n",
    "    padded_mzs: torch.Tensor,\n",
    "    padded_intensity: torch.Tensor,\n",
    "    bin_cells: torch.Tensor,\n",
    "    pool_method: Literal['sum','max', 'avg'] = \"sum\",\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    # 生成掩码张量 [n_spec, num_peaks, num_bins]\n",
    "    mask = (padded_mzs.unsqueeze(-1) >= bin_cells[:, 0]) & (padded_mzs.unsqueeze(-1) < bin_cells[:, 1])\n",
    "    mask = mask.float()\n",
    "    \n",
    "    # 批量池化计算\n",
    "    if pool_method == \"sum\":\n",
    "        return torch.einsum('spb,sp->sb', mask, padded_intensity)\n",
    "    elif pool_method == \"max\":\n",
    "        expanded_intensity = padded_intensity.unsqueeze(-1) * mask  # [n_spec, num_peaks, num_bins]\n",
    "        return torch.where(mask.any(dim=1), \n",
    "                          expanded_intensity.max(dim=1).values, \n",
    "                          torch.zeros_like(expanded_intensity[:,0,:]))\n",
    "    elif pool_method == \"avg\":\n",
    "        sum_result = torch.einsum('spb,sp->sb', mask, padded_intensity)\n",
    "        counts = mask.sum(dim=1)  # [n_spec, num_bins]\n",
    "        return sum_result / counts.clamp(min=1e-8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported pooling method: {pool_method}\")\n",
    "    \n",
    "@torch.no_grad()\n",
    "def binning_cpu(\n",
    "    mzs: List[torch.Tensor],\n",
    "    intensities: List[torch.Tensor],\n",
    "    bin_cells: torch.Tensor,\n",
    "    pool_method: Literal['sum','max', 'avg'] = \"sum\",\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    work_device: torch.device = torch.device('cpu'),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    # 参数校验\n",
    "    assert len(mzs) == len(intensities), \"M/Z与强度列表长度不一致\"\n",
    "    if output_device is None:\n",
    "        output_device = work_device\n",
    "\n",
    "    # 设备转移检查\n",
    "    if bin_cells.device != work_device:\n",
    "        bin_cells = bin_cells.to(work_device)\n",
    "\n",
    "    def process_batch(batch):\n",
    "        \n",
    "        mz_batch, intensity_batch = zip(*batch)\n",
    "        mz_batch = list(mz_batch)  # 转换为列表\n",
    "        intensity_batch = list(intensity_batch)  # 转换为列表\n",
    "        \n",
    "        nt_mz = nested_tensor(mz_batch,device=work_device)\n",
    "        nt_intensity = nested_tensor(intensity_batch)\n",
    "        \n",
    "        padded_mz = nt_mz.to_padded_tensor(0.0)\n",
    "        padded_intensity = nt_intensity.to_padded_tensor(0.0)\n",
    "        \n",
    "        result = binning_step(padded_mz, padded_intensity, bin_cells, pool_method)\n",
    "        \n",
    "        if output_device != work_device:  # 仅当目标设备不同时才转移\n",
    "            result = result.to(output_device)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    batches = [\n",
    "        list(zip(mzs[i:i+batch_size], intensities[i:i+batch_size]))\n",
    "        for i in range(0, len(mzs), batch_size)\n",
    "    ]\n",
    "\n",
    "    bag = db.from_sequence(batches, npartitions=num_workers)\n",
    "    results = bag.map(process_batch).compute(scheduler='threads', num_workers=num_workers)\n",
    "\n",
    "    return torch.cat(results, dim=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def binning_cuda(\n",
    "    mzs: List[torch.Tensor],\n",
    "    intensities: List[torch.Tensor],\n",
    "    bin_cells: torch.Tensor,\n",
    "    pool_method: Literal['sum','max', 'avg'] = \"sum\",\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    # 参数校验与设备设置\n",
    "    assert len(mzs) == len(intensities), \"M/Z与强度列表长度不一致\"\n",
    "    output_device = output_device or work_device  # 设置默认输出设备\n",
    "\n",
    "    # 设备转移检查\n",
    "    if bin_cells.device != work_device:\n",
    "        bin_cells = bin_cells.to(work_device, non_blocking=True)\n",
    "\n",
    "    class Worker:\n",
    "        def __init__(self):\n",
    "            # 四阶段流定义\n",
    "            self.transfer_stream = torch.cuda.Stream(device=work_device)  # 数据传输流\n",
    "            self.padding_stream = torch.cuda.Stream(device=work_device)  # padding流\n",
    "            self.compute_stream = torch.cuda.Stream(device=work_device)   # 计算流\n",
    "            self.output_stream = torch.cuda.Stream(device=work_device)    # 结果回传流\n",
    "            \n",
    "            # 同步事件\n",
    "            self.transfer_done = torch.cuda.Event()\n",
    "            self.padding_done = torch.cuda.Event()\n",
    "            self.compute_done = torch.cuda.Event()\n",
    "\n",
    "    workers = [Worker() for _ in range(num_workers)]\n",
    "\n",
    "    def process_worker(batch, worker: Worker):\n",
    "        result = None\n",
    "        \n",
    "        # 阶段1：数据传输 (CPU->GPU)\n",
    "        with torch.cuda.stream(worker.transfer_stream):\n",
    "            # 异步传输原始数据\n",
    "            mz_batch = [t.to(work_device, non_blocking=True) for t, _ in batch]\n",
    "            intensity_batch = [t.to(work_device, non_blocking=True) for _, t in batch]\n",
    "            worker.transfer_done.record()\n",
    "\n",
    "        # 阶段2：Padding处理\n",
    "        with torch.cuda.stream(worker.padding_stream):\n",
    "            worker.transfer_done.wait()\n",
    "            \n",
    "            max_len = max(t.shape[0] for t in mz_batch)\n",
    "            padded_mz = torch.zeros(len(batch), max_len, device=work_device)\n",
    "            padded_intensity = torch.zeros_like(padded_mz)\n",
    "            \n",
    "            for i, (mz, intensity) in enumerate(zip(mz_batch, intensity_batch)):\n",
    "                padded_mz[i, :len(mz)] = mz\n",
    "                padded_intensity[i, :len(intensity)] = intensity\n",
    "            worker.padding_done.record()\n",
    "\n",
    "        # 阶段3：Binning计算\n",
    "        with torch.cuda.stream(worker.compute_stream):\n",
    "            worker.padding_done.wait()\n",
    "            result = binning_step(padded_mz, padded_intensity, bin_cells, pool_method)\n",
    "            worker.compute_done.record()\n",
    "\n",
    "        # 阶段4：结果回传 (GPU->目标设备)\n",
    "        with torch.cuda.stream(worker.output_stream):\n",
    "            worker.compute_done.wait()\n",
    "            if output_device != work_device:  # 仅当目标设备不同时才转移\n",
    "                result = result.to(output_device, non_blocking=True)\n",
    "            return result\n",
    "\n",
    "    # 流水线执行\n",
    "    results = []\n",
    "    for batch_idx in range(0, len(mzs), batch_size):\n",
    "        worker = workers[batch_idx % num_workers]\n",
    "        batch = list(zip(\n",
    "            mzs[batch_idx:batch_idx+batch_size],\n",
    "            intensities[batch_idx:batch_idx+batch_size]\n",
    "        ))\n",
    "        results.append(process_worker(batch, worker))\n",
    "\n",
    "    # 同步所有流并返回结果\n",
    "    torch.cuda.synchronize()\n",
    "    return torch.cat(results, dim=0)\n",
    "\n",
    "def binning(\n",
    "    mzs: List[torch.Tensor],\n",
    "    intensities: List[torch.Tensor],\n",
    "    binning_window: Tuple[float,float,float] = (50.0, 1000.0, 1.0),\n",
    "    pool_method: Literal['sum','max', 'avg'] = \"sum\",\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    work_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    output_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    # 参数校验\n",
    "    assert len(binning_window) == 3, \"分箱窗口需要包含三个参数（min_mz, max_mz, bin_size）\"\n",
    "    min_mz, max_mz, bin_size = binning_window\n",
    "    assert min_mz < max_mz, \"最小m/z必须小于最大m/z\"\n",
    "    assert bin_size > 0, \"分箱尺寸必须大于0\"\n",
    "\n",
    "    # 自动推断工作设备\n",
    "    _work_device = resolve_device(work_device, mzs[0].device)\n",
    "    # 自动推断输出设备\n",
    "    _output_device = resolve_device(output_device, _work_device)\n",
    "\n",
    "    # 生成分箱单元格并转移到目标设备\n",
    "    bin_cells = infer_bin_cells(min_mz, max_mz, bin_size).to(_work_device)\n",
    "\n",
    "    # 选择执行路径\n",
    "    if _work_device.type.startswith('cuda'):\n",
    "        return binning_cuda(\n",
    "            mzs=mzs,\n",
    "            intensities=intensities,\n",
    "            bin_cells=bin_cells,\n",
    "            pool_method=pool_method,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device,\n",
    "        )\n",
    "    else:\n",
    "        return binning_cpu(\n",
    "            mzs=mzs,\n",
    "            intensities=intensities,\n",
    "            bin_cells=bin_cells,\n",
    "            pool_method=pool_method,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0340f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "mzs = [tensor([ 50.2000, 100.5000, 200.8000]),tensor([ 99.9000, 150.3000, 250.1000, 300.2000])]\n",
    "intensities = [tensor([1., 2., 3.]), tensor([4., 5., 6., 7.])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = binning(mzs, intensities, (50, 300, 50), pool_method='sum', work_device=\"cuda\", output_device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a79a926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daiql/miniconda3/envs/MS310/lib/python3.10/site-packages/torch/nested/__init__.py:228: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    }
   ],
   "source": [
    "result = binning(mzs, intensities, (50, 300, 50), pool_method='sum', work_device=\"cpu\", output_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1311cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 50, 100],\n",
       "        [100, 150],\n",
       "        [150, 200],\n",
       "        [200, 250],\n",
       "        [250, 300]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_bin_cells(50,300,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41fceded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 3., 0.],\n",
       "        [4., 0., 5., 0., 6.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
