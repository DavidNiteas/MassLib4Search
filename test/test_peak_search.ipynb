{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1867d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "from typing import Literal, Optional, Union\n",
    "\n",
    "@torch.no_grad()\n",
    "def broadcast(\n",
    "    Q: Tensor,\n",
    "    R: Tensor\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    \n",
    "    Q_expanded = Q.view(*Q.shape, *(1,)*R.ndim)\n",
    "    R_expanded = R.view(*(1,)*Q.ndim, *R.shape)\n",
    "    \n",
    "    return Q_expanded, R_expanded\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_delta_matrix(\n",
    "    Q: Tensor,\n",
    "    R: Tensor\n",
    ") -> Tensor:\n",
    "    \n",
    "    return torch.abs(Q - R)\n",
    "\n",
    "@torch.no_grad()\n",
    "def ppm_convert(\n",
    "    D: Tensor,\n",
    "    R: Tensor,\n",
    ") -> Tensor:\n",
    "    return D * (1e6 / R)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_bool_matrix(\n",
    "    D: Tensor,\n",
    "    T: float\n",
    ") -> Tensor:\n",
    "    return D <= T\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_indices(\n",
    "    B: Tensor,\n",
    ") -> Tensor:\n",
    "    return B.nonzero(as_tuple=False)\n",
    "\n",
    "@torch.no_grad()\n",
    "def indices_offset(\n",
    "    I: Tensor,\n",
    "    qry_offset: int,\n",
    "    ref_offset: int,\n",
    ") -> Tensor:\n",
    "    I[:, 0] += qry_offset\n",
    "    I[:, 1] += ref_offset\n",
    "    return I\n",
    "\n",
    "@torch.no_grad()\n",
    "def adduct_co_occurrence_filter(\n",
    "    I: Tensor,\n",
    "    threshold: int,\n",
    "    dim: int,\n",
    "    D: Tensor,\n",
    ") -> Union[Tensor, Tuple[Tensor, Tensor]]:\n",
    "    \n",
    "    if I.size(0) == 0:\n",
    "        return (I, D) if D is not None else I\n",
    "    \n",
    "    # 统计有效参考样本\n",
    "    _, ref_counts = torch.unique(I[:, dim], return_counts=True)\n",
    "    valid_mask = ref_counts[I[:, dim]] >= threshold\n",
    "    \n",
    "    # 同步过滤逻辑\n",
    "    return I[valid_mask], D[valid_mask]\n",
    "\n",
    "@torch.no_grad()\n",
    "def mz_search_cpu(\n",
    "    qry_ions: Tensor,\n",
    "    ref_mzs: Tensor,\n",
    "    mz_tolerance: float = 3,\n",
    "    mz_tolerance_type: Literal['ppm','Da'] = 'ppm',\n",
    "    query_RTs: Optional[Tensor] = None,\n",
    "    ref_RTs: Optional[Tensor] = None,\n",
    "    RT_tolerance: float = 0.1,\n",
    "    adduct_co_occurrence_threshold: int = 1,\n",
    "    chunk_size: int = 5120,\n",
    "    work_device: torch.device = torch.device(\"cpu\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"改进的m/z搜索函数，支持设备管理和分块过滤\"\"\"\n",
    "    output_device = output_device or work_device\n",
    "    qry_ions = qry_ions.to(work_device)\n",
    "    ref_mzs = ref_mzs.to(work_device)\n",
    "    query_RTs = query_RTs.to(work_device) if query_RTs is not None else None\n",
    "    ref_RTs = ref_RTs.to(work_device) if ref_RTs is not None else None\n",
    "\n",
    "    all_indices, all_deltas = [], []\n",
    "    q_dim = len(qry_ions.shape)\n",
    "\n",
    "    for q_idx, q_chunk in enumerate(qry_ions.split(chunk_size)):\n",
    "        q_offset = q_idx * chunk_size\n",
    "        current_ref_offset = 0\n",
    "        chunk_indices, chunk_deltas = [], []\n",
    "\n",
    "        for r_chunk in ref_mzs.split(chunk_size):\n",
    "            Q, R = broadcast(q_chunk.to(work_device), r_chunk.to(work_device))\n",
    "            delta = torch.abs(Q - R)\n",
    "\n",
    "            if mz_tolerance_type == 'ppm':\n",
    "                delta = delta * (1e6 / R.clamp(min=1e-6))\n",
    "\n",
    "            mz_mask = delta <= mz_tolerance\n",
    "\n",
    "            if query_RTs is not None and ref_RTs is not None:\n",
    "                rt_q = query_RTs[q_offset:q_offset+len(q_chunk)]\n",
    "                rt_r = ref_RTs[current_ref_offset:current_ref_offset+len(r_chunk)]\n",
    "                rt_q, rt_r = broadcast(rt_q, rt_r)\n",
    "                rt_delta = torch.abs(rt_q - rt_r)\n",
    "                mz_mask &= rt_delta <= RT_tolerance\n",
    "\n",
    "            local_indices = mz_mask.nonzero(as_tuple=False)\n",
    "            if local_indices.size(0) > 0:\n",
    "                global_indices = indices_offset(local_indices, q_offset, current_ref_offset)\n",
    "                chunk_indices.append(global_indices)\n",
    "                chunk_deltas.append(delta[mz_mask])\n",
    "\n",
    "            current_ref_offset += len(r_chunk)\n",
    "\n",
    "        if chunk_indices:\n",
    "            I_chunk = torch.cat(chunk_indices)\n",
    "            D_chunk = torch.cat(chunk_deltas)\n",
    "\n",
    "            if adduct_co_occurrence_threshold > 1:\n",
    "                I_chunk, D_chunk = adduct_co_occurrence_filter(\n",
    "                    I_chunk, adduct_co_occurrence_threshold, q_dim, D_chunk\n",
    "                )\n",
    "\n",
    "            all_indices.append(I_chunk)\n",
    "            all_deltas.append(D_chunk)\n",
    "\n",
    "    I = torch.cat(all_indices) if all_indices else torch.empty((0, 2), dtype=torch.long, device=work_device)\n",
    "    D = torch.cat(all_deltas) if all_deltas else torch.empty((0,), dtype=ref_mzs.dtype, device=work_device)\n",
    "\n",
    "    return I.to(output_device), D.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e535c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.tensor([100.0, 200.0, 300.0])\n",
    "ref = torch.tensor([100.003, 199.995, 305.0])\n",
    "I, D = mz_search_cpu(qry, ref, mz_tolerance=50, mz_tolerance_type='ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a848471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0c83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9826, 25.0250])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b877389",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mz_search_cuda(\n",
    "    qry_ions: torch.Tensor,\n",
    "    ref_mzs: torch.Tensor,\n",
    "    mz_tolerance: float = 3,\n",
    "    mz_tolerance_type: Literal['ppm','Da'] = 'ppm',\n",
    "    query_RTs: Optional[torch.Tensor] = None,\n",
    "    ref_RTs: Optional[torch.Tensor] = None,\n",
    "    RT_tolerance: float = 0.1,\n",
    "    adduct_co_occurrence_threshold: int = 1,\n",
    "    chunk_size: int = 5120,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    # 设备初始化\n",
    "    output_device = output_device or work_device\n",
    "    input_stream = torch.cuda.Stream()\n",
    "    compute_stream = torch.cuda.Stream()\n",
    "    output_stream = torch.cuda.Stream()\n",
    "    \n",
    "    # 数据预迁移\n",
    "    with torch.cuda.stream(input_stream):\n",
    "        qry_ions = qry_ions.to(work_device, non_blocking=True)\n",
    "        ref_mzs = ref_mzs.to(work_device, non_blocking=True)\n",
    "        query_RTs = query_RTs.to(work_device, non_blocking=True) if query_RTs is not None else None\n",
    "        ref_RTs = ref_RTs.to(work_device, non_blocking=True) if ref_RTs is not None else None\n",
    "    \n",
    "    # 分块管理\n",
    "    q_chunks = list(qry_ions.split(chunk_size))\n",
    "    r_chunks = list(ref_mzs.split(chunk_size))\n",
    "    \n",
    "    # 流水线控制\n",
    "    all_indices, all_deltas = [], []\n",
    "    \n",
    "    for q_idx, q_chunk in enumerate(q_chunks):\n",
    "        q_offset = q_idx * chunk_size\n",
    "        current_ref_offset = 0\n",
    "        chunk_indices, chunk_deltas = [], []\n",
    "        \n",
    "        # 初始化参考分块流水线\n",
    "        with torch.cuda.stream(input_stream):\n",
    "            current_r = r_chunks[0].to(work_device, non_blocking=True)\n",
    "        \n",
    "        for r_idx in range(len(r_chunks)):\n",
    "            # 预取下一分块\n",
    "            next_r = r_chunks[r_idx+1] if r_idx+1 < len(r_chunks) else None\n",
    "            if next_r is not None:\n",
    "                with torch.cuda.stream(input_stream):\n",
    "                    next_r = next_r.to(work_device, non_blocking=True)\n",
    "            \n",
    "            # 计算逻辑\n",
    "            with torch.cuda.stream(compute_stream):\n",
    "                torch.cuda.current_stream().wait_stream(input_stream)\n",
    "                \n",
    "                Q, R = broadcast(q_chunk, current_r)\n",
    "                delta = torch.abs(Q - R)\n",
    "                \n",
    "                if mz_tolerance_type == 'ppm':\n",
    "                    delta = delta * (1e6 / R.clamp(min=1e-6))\n",
    "                \n",
    "                mz_mask = delta <= mz_tolerance\n",
    "                \n",
    "                if query_RTs is not None and ref_RTs is not None:\n",
    "                    rt_q = query_RTs[q_offset:q_offset+len(q_chunk)]\n",
    "                    rt_r = ref_RTs[current_ref_offset:current_ref_offset+len(current_r)]\n",
    "                    rt_q, rt_r = broadcast(rt_q, rt_r)\n",
    "                    rt_delta = torch.abs(rt_q - rt_r)\n",
    "                    mz_mask &= rt_delta <= RT_tolerance\n",
    "                \n",
    "                local_indices = mz_mask.nonzero(as_tuple=False)\n",
    "                if local_indices.size(0) > 0:\n",
    "                    global_indices = indices_offset(local_indices, q_offset, current_ref_offset)\n",
    "                    chunk_indices.append(global_indices)\n",
    "                    chunk_deltas.append(delta[mz_mask])\n",
    "            \n",
    "            # 结果回传\n",
    "            with torch.cuda.stream(output_stream):\n",
    "                torch.cuda.current_stream().wait_stream(compute_stream)\n",
    "                if chunk_indices:\n",
    "                    all_indices.append(torch.cat(chunk_indices).to(output_device, non_blocking=True))\n",
    "                    all_deltas.append(torch.cat(chunk_deltas).to(output_device, non_blocking=True))\n",
    "            \n",
    "            current_ref_offset += current_r.size(0)\n",
    "            current_r = next_r\n",
    "        \n",
    "        # 分块内加合物过滤\n",
    "        with torch.cuda.stream(compute_stream):\n",
    "            if adduct_co_occurrence_threshold > 1 and chunk_indices:\n",
    "                I_chunk = torch.cat(chunk_indices)\n",
    "                D_chunk = torch.cat(chunk_deltas)\n",
    "                I_chunk, D_chunk = adduct_co_occurrence_filter(\n",
    "                    I_chunk, adduct_co_occurrence_threshold, \n",
    "                    len(qry_ions.shape), D=D_chunk\n",
    "                )\n",
    "                chunk_indices = [I_chunk]\n",
    "                chunk_deltas = [D_chunk]\n",
    "    \n",
    "    # 最终同步\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # 结果整合\n",
    "    with torch.cuda.stream(output_stream):\n",
    "        I = torch.cat(all_indices) if all_indices else torch.empty((0,2), dtype=torch.long, device=output_device)\n",
    "        D = torch.cat(all_deltas) if all_deltas else torch.empty((0,), dtype=ref_mzs.dtype, device=output_device)\n",
    "        \n",
    "        # 维度校正\n",
    "        if I.size(0) == 0:\n",
    "            I = I.reshape(0, len(qry_ions.shape)+len(ref_mzs.shape))\n",
    "            D = D.reshape(0)\n",
    "    \n",
    "    return I, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dce598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.tensor([100.0, 200.0, 300.0])\n",
    "ref = torch.tensor([100.003, 199.995, 305.0])\n",
    "I, D = mz_search_cuda(qry, ref, mz_tolerance=50, mz_tolerance_type='ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02fe8bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7baa53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9826, 25.0250], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_device(\n",
    "    device: Union[str, torch.device, Literal['auto']], \n",
    "    default: torch.device\n",
    ") -> torch.device:\n",
    "    if isinstance(device, torch.device):\n",
    "        return device\n",
    "    if device == 'auto':\n",
    "        return default\n",
    "    if device == 'cuda':\n",
    "        device = 'cuda:0'\n",
    "    return torch.device(device)\n",
    "\n",
    "def mz_search(\n",
    "    qry_ions: torch.Tensor,\n",
    "    ref_mzs: torch.Tensor,\n",
    "    mz_tolerance: float = 3,\n",
    "    mz_tolerance_type: Literal['ppm','Da'] = 'ppm',\n",
    "    query_RTs: Optional[torch.Tensor] = None,\n",
    "    ref_RTs: Optional[torch.Tensor] = None,\n",
    "    RT_tolerance: float = 0.1,\n",
    "    adduct_co_occurrence_threshold: int = 1,\n",
    "    chunk_size: int = 5120,\n",
    "    work_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    output_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    # 设备自动推断\n",
    "    _work_device = resolve_device(work_device, qry_ions.device)\n",
    "    _output_device = resolve_device(output_device, _work_device)\n",
    "    \n",
    "    # 设备分发逻辑\n",
    "    if _work_device.type.startswith('cuda'):\n",
    "        return mz_search_cuda(\n",
    "            qry_ions, ref_mzs, \n",
    "            mz_tolerance=mz_tolerance,\n",
    "            mz_tolerance_type=mz_tolerance_type,\n",
    "            query_RTs=query_RTs,\n",
    "            ref_RTs=ref_RTs,\n",
    "            RT_tolerance=RT_tolerance,\n",
    "            adduct_co_occurrence_threshold=adduct_co_occurrence_threshold,\n",
    "            chunk_size=chunk_size,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )\n",
    "    else:\n",
    "        return mz_search_cpu(\n",
    "            qry_ions, ref_mzs,\n",
    "            mz_tolerance=mz_tolerance,\n",
    "            mz_tolerance_type=mz_tolerance_type,\n",
    "            query_RTs=query_RTs,\n",
    "            ref_RTs=ref_RTs,\n",
    "            RT_tolerance=RT_tolerance,\n",
    "            adduct_co_occurrence_threshold=adduct_co_occurrence_threshold,\n",
    "            chunk_size=chunk_size,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d37fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.tensor([100.0, 200.0, 300.0])\n",
    "ref = torch.tensor([100.003, 199.995, 305.0])\n",
    "I, D = mz_search(qry, ref, mz_tolerance=50, mz_tolerance_type='ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a86458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ff6ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9826, 25.0250])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355a6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = torch.tensor([100.0, 200.0, 300.0])\n",
    "ref = torch.tensor([100.003, 199.995, 305.0])\n",
    "I, D = mz_search(qry, ref, mz_tolerance=50, mz_tolerance_type='ppm',work_device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938e7d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02bb1270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9826, 25.0250], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
