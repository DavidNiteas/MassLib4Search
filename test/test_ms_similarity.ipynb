{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4babd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masslib4search.snaps.MassSearchTools.utils.similarity import ms_similarity\n",
    "import torch\n",
    "import dask.bag as db\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee35289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ms_entropy as me\n",
    "import dask\n",
    "import dask.bag as db\n",
    "from typing import List, Callable, Optional, Union, Literal\n",
    "\n",
    "def ms_entropy_similarity(\n",
    "    query_spec: torch.Tensor, # (n_peaks, 2)\n",
    "    ref_spec: torch.Tensor, # (n_peaks, 2)\n",
    ") -> torch.Tensor: # (1,1)\n",
    "    sim = me.calculate_entropy_similarity(query_spec, ref_spec)\n",
    "    return torch.tensor([[sim]], device=query_spec.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def spectrum_similarity_cpu(\n",
    "    query: List[List[torch.Tensor]],  # Queue[List[(n_peaks, 2)]]\n",
    "    ref: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cpu\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    "    dask_mode: Optional[Literal[\"threads\", \"processes\", \"single-threaded\"]] = None,\n",
    ") -> List[torch.Tensor]: # Queue[(len(query_block), len(ref_block)]\n",
    "\n",
    "    # 构建配对序列\n",
    "    bag_queue = []\n",
    "    for query_block, ref_block in zip(query, ref):\n",
    "        query_block_bag = db.from_sequence(query_block, npartitions=num_dask_workers)\n",
    "        ref_block_bag = db.from_sequence(ref_block, npartitions=num_dask_workers)\n",
    "        pairs_bag = query_block_bag.product(ref_block_bag)\n",
    "        results_bag = pairs_bag.map(lambda x: sim_operator(x[0].to(work_device), x[1].to(work_device)))\n",
    "        results_bag = results_bag.map(lambda s: s.to(output_device or work_device))\n",
    "        bag_queue.append(results_bag)\n",
    "    \n",
    "    # 使用dask并行计算\n",
    "    queue_results = dask.compute(bag_queue, scheduler=dask_mode, num_workers=num_dask_workers)[0]\n",
    "    # 合并结果\n",
    "    queue_results_bag = db.from_sequence(zip(queue_results,query,ref), npartitions=num_dask_workers)\n",
    "    queue_results_bag = queue_results_bag.map(lambda x: torch.cat(x[0], dim=0).reshape(len(x[1]), len(x[2])))\n",
    "    queue_results = queue_results_bag.compute(scheduler='threads', num_workers=num_dask_workers)\n",
    "    \n",
    "    return queue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66d2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cpu_spectra():\n",
    "    \"\"\"生成CPU测试数据\"\"\"\n",
    "    return [\n",
    "        # 格式：(m/z, intensity)\n",
    "        torch.tensor([[100.0, 1.0], [200.0, 0.8], [300.0, 0.5]], dtype=torch.float32),\n",
    "        torch.tensor([[150.0, 0.9], [250.0, 0.7], [350.0, 0.6]], dtype=torch.float32)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86edce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_block = sample_cpu_spectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00827ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000, 0.0000],\n",
       "         [0.0000, 1.0000]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_similarity_cpu([spec_block],[spec_block],ms_entropy_similarity,dask_mode=\"threads\",num_dask_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9480242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def spectrum_similarity_cuda_block(\n",
    "    query: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    ref: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    num_cuda_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    output_device = output_device or work_device\n",
    "    torch.cuda.set_device(work_device)\n",
    "    \n",
    "    # 为每个worker创建三个专用流\n",
    "    worker_resources = [\n",
    "        {\n",
    "            'h2d_stream': torch.cuda.Stream(),  # 数据传入流\n",
    "            'compute_stream': torch.cuda.Stream(),  # 计算流\n",
    "            'd2h_stream': torch.cuda.Stream(),  # 结果传出流\n",
    "            'h2d_event': torch.cuda.Event(),\n",
    "            'compute_event': torch.cuda.Event(),\n",
    "        }\n",
    "        for _ in range(num_cuda_workers)\n",
    "    ]\n",
    "    \n",
    "    # 预分配设备内存\n",
    "    results = torch.zeros(len(query), len(ref), device=output_device)\n",
    "\n",
    "    # 异步执行函数\n",
    "    def _process_pair(q_idx, r_idx, worker_id):\n",
    "        resources = worker_resources[worker_id]\n",
    "        \n",
    "        # 修改后的Stage 1：同时传输query和ref\n",
    "        with torch.cuda.stream(resources['h2d_stream']):\n",
    "            q_tensor = query[q_idx].pin_memory().to(work_device, non_blocking=True)\n",
    "            r_tensor = ref[r_idx].pin_memory().to(work_device, non_blocking=True)\n",
    "            resources['h2d_event'].record()\n",
    "        \n",
    "        # Stage 2保持不变（但使用新传输的r_tensor）\n",
    "        with torch.cuda.stream(resources['compute_stream']):\n",
    "            resources['h2d_event'].wait()\n",
    "            similarity = sim_operator(q_tensor, r_tensor)  # 改用动态传输的ref\n",
    "            resources['compute_event'].record()\n",
    "        \n",
    "        # Stage 3: 结果传回output_device\n",
    "        with torch.cuda.stream(resources['d2h_stream']):\n",
    "            resources['compute_event'].wait()\n",
    "            if output_device != work_device:\n",
    "                results[q_idx, r_idx] = similarity.to(output_device, non_blocking=True)\n",
    "            else:\n",
    "                results[q_idx, r_idx] = similarity\n",
    "\n",
    "    # 任务调度器\n",
    "    worker_cycle = cycle(range(num_cuda_workers))\n",
    "    \n",
    "    # 提交任务到流水线\n",
    "    futures = []\n",
    "    for q_idx in range(len(query)):\n",
    "        for r_idx in range(len(ref)):\n",
    "            worker_id = next(worker_cycle)\n",
    "            futures.append((q_idx, r_idx, worker_id))\n",
    "    \n",
    "    # 启动所有异步任务\n",
    "    for q_idx, r_idx, worker_id in futures:\n",
    "        _process_pair(q_idx, r_idx, worker_id)\n",
    "    \n",
    "    # 等待所有流完成\n",
    "    for worker in worker_resources:\n",
    "        worker['d2h_stream'].synchronize()\n",
    "    \n",
    "    return results\n",
    "\n",
    "@torch.no_grad()\n",
    "def spectrum_similarity_cuda(\n",
    "    query: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    ref: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    num_cuda_workers: int = 4,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> List[torch.Tensor]:\n",
    "    \n",
    "    block_bag = db.from_sequence(zip(query, ref), npartitions=num_dask_workers)\n",
    "    block_bag = block_bag.map(lambda x: spectrum_similarity_cuda_block(\n",
    "        x[0], x[1], sim_operator, num_cuda_workers, work_device, output_device\n",
    "    ))\n",
    "    results = block_bag.compute(scheduler='threads', num_workers=num_dask_workers)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a18d8a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 1.],\n",
       "         [1., 1.]], device='cuda:0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_similarity_cuda(\n",
    "    [spec_block],[spec_block],\n",
    "    lambda x,y: torch.tensor([[1.0]]),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
