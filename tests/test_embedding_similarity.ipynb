{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba94bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Callable, Literal, Optional, Union\n",
    "\n",
    "@torch.no_grad()\n",
    "def tanimoto(va: torch.Tensor, vb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Tanimoto系数\"\"\"\n",
    "    vp = torch.sum(va.unsqueeze(-2) * vb.unsqueeze(-3), dim=-1)\n",
    "    vas = torch.sum(va**2, dim=-1, keepdim=True)\n",
    "    vbs = torch.sum(vb**2, dim=-1, keepdim=True)\n",
    "    return vp / (vas + vbs.transpose(-1,-2) - vp + 1e-6)\n",
    "\n",
    "@torch.no_grad()\n",
    "def cosine(va: torch.Tensor, vb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"余弦相似度\"\"\"\n",
    "    norm_a = torch.norm(va, p=2, dim=-1, keepdim=True)\n",
    "    norm_b = torch.norm(vb, p=2, dim=-1, keepdim=True)\n",
    "    return torch.matmul(va, vb.transpose(-1,-2)) / (norm_a * norm_b.transpose(-1,-2) + 1e-6)\n",
    "\n",
    "@torch.no_grad()\n",
    "def dot(va: torch.Tensor, vb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"点积\"\"\"\n",
    "    return torch.matmul(va, vb.transpose(-1,-2))\n",
    "\n",
    "@torch.no_grad()\n",
    "def jaccard(va: torch.Tensor, vb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Jaccard系数\"\"\"\n",
    "    intersection = torch.logical_and(va.unsqueeze(-2), vb.unsqueeze(-3))\n",
    "    union = torch.logical_or(va.unsqueeze(-2), vb.unsqueeze(-3))\n",
    "    return torch.sum(intersection.float(), dim=-1) / (torch.sum(union.float(), dim=-1) + 1e-6)\n",
    "\n",
    "@torch.no_grad()\n",
    "def pearson(va: torch.Tensor, vb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"皮尔逊相关系数\"\"\"\n",
    "    mean_a = torch.mean(va, dim=-1, keepdim=True)\n",
    "    mean_b = torch.mean(vb, dim=-1, keepdim=True)\n",
    "    centered_a = va - mean_a\n",
    "    centered_b = vb - mean_b\n",
    "    numerator = torch.matmul(centered_a, centered_b.transpose(-1,-2))\n",
    "    denominator = torch.sqrt(\n",
    "        torch.sum(centered_a**2, dim=-1, keepdim=True) *\n",
    "        torch.sum(centered_b**2, dim=-1, keepdim=True).transpose(-1,-2)\n",
    "    )\n",
    "    return numerator / (denominator + 1e-6)\n",
    "\n",
    "@torch.no_grad()\n",
    "def embedding_similarity_cpu(\n",
    "    query: torch.Tensor, # shape: (n_q, dim), dtype: float32\n",
    "    ref: torch.Tensor, # shape: (n_r, dim), dtype: float32\n",
    "    chunk_size: int = 5120,\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = cosine,\n",
    "    work_device: torch.device = torch.device(\"cpu\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor: # shape: (n_q, n_r), dtype: float32\n",
    "    \n",
    "    # 自动选择设备\n",
    "    output_device = output_device or work_device\n",
    "    query = query.to(work_device)\n",
    "    ref = ref.to(work_device)\n",
    "    \n",
    "    # 分块计算逻辑    \n",
    "    results = []\n",
    "    for q_chunk in query.split(chunk_size):\n",
    "        chunk_results = []\n",
    "        for r_chunk in ref.split(chunk_size):\n",
    "            res = sim_operator(q_chunk, r_chunk).to(output_device)\n",
    "            chunk_results.append(res)\n",
    "        results.append(torch.cat(chunk_results, dim=1))\n",
    "    return torch.cat(results).to(output_device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def embedding_similarity_gpu(\n",
    "    query: torch.Tensor,\n",
    "    ref: torch.Tensor,\n",
    "    chunk_size: int = 5120,\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = cosine,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    output_device = output_device or work_device\n",
    "    torch.cuda.set_device(work_device)\n",
    "    \n",
    "    # 创建三阶段流\n",
    "    h2d_stream = torch.cuda.Stream()  # 主机到设备传输流\n",
    "    compute_stream = torch.cuda.Stream()  # 计算流\n",
    "    d2h_stream = torch.cuda.Stream()  # 设备到主机传输流\n",
    "    \n",
    "    results = []\n",
    "    ref_chunks = list(ref.split(chunk_size))\n",
    "    \n",
    "    # 预取第一个ref chunk\n",
    "    current_ref = ref_chunks[0].to(work_device, non_blocking=True)\n",
    "    \n",
    "    for q_chunk in query.to(work_device).split(chunk_size):\n",
    "        chunk_results = []\n",
    "        next_ref_iter = iter(ref_chunks[1:] + [None])\n",
    "        \n",
    "        for i in range(len(ref_chunks)):\n",
    "            # 流水线阶段1：预取下一个chunk\n",
    "            with torch.cuda.stream(h2d_stream):\n",
    "                next_ref = next(next_ref_iter, None)\n",
    "                if next_ref is not None:\n",
    "                    next_ref = next_ref.to(work_device, non_blocking=True)\n",
    "            \n",
    "            # 流水线阶段2：执行计算\n",
    "            with torch.cuda.stream(compute_stream):\n",
    "                sim = sim_operator(q_chunk, current_ref)\n",
    "            \n",
    "            # 流水线阶段3：传输结果\n",
    "            with torch.cuda.stream(d2h_stream):\n",
    "                sim_cpu = sim.to(output_device,non_blocking=True)\n",
    "                chunk_results.append(sim_cpu)\n",
    "            \n",
    "            # 更新当前ref并同步流\n",
    "            current_ref = next_ref if next_ref is not None else current_ref\n",
    "            torch.cuda.current_stream().wait_stream(h2d_stream)\n",
    "            torch.cuda.current_stream().wait_stream(d2h_stream)\n",
    "        \n",
    "        # 等待所有操作完成\n",
    "        torch.cuda.synchronize()\n",
    "        results.append(torch.cat(chunk_results, dim=1))\n",
    "    \n",
    "    return torch.cat(results).to(output_device)\n",
    "\n",
    "def embedding_similarity(\n",
    "    query: torch.Tensor,\n",
    "    ref: torch.Tensor,\n",
    "    chunk_size: int = 5120,\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = cosine,\n",
    "    work_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    output_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    ") -> torch.Tensor:\n",
    "    # 设备类型转换逻辑\n",
    "    def resolve_device(\n",
    "        device: Union[str, torch.device, Literal['auto']], \n",
    "        default: torch.device\n",
    "    ) -> torch.device:\n",
    "        if isinstance(device, torch.device):\n",
    "            return device\n",
    "        if device == 'auto':\n",
    "            return default\n",
    "        if device == 'cuda':\n",
    "            device = 'cuda:0'\n",
    "        return torch.device(device)\n",
    "\n",
    "    # 自动推断工作设备\n",
    "    _work_device = resolve_device(work_device, query.device)\n",
    "    # 自动推断输出设备\n",
    "    _output_device = resolve_device(output_device, _work_device)\n",
    "\n",
    "    # 分发到具体实现\n",
    "    if _work_device.type.startswith('cuda'):\n",
    "        return embedding_similarity_gpu(\n",
    "            query, ref, chunk_size, sim_operator,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )\n",
    "    else:\n",
    "        return embedding_similarity_cpu(\n",
    "            query, ref, chunk_size, sim_operator,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "681e3e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 测试结果汇总"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 设备控制测试: ✅ PASSED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 计算精度测试: ✅ PASSED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 分块处理测试: ✅ PASSED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 设备转移测试: ✅ PASSED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 边界情况测试: ✅ PASSED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "class TestRunner:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.cuda_available = torch.cuda.is_available()\n",
    "        \n",
    "    def setup(self):\n",
    "        self.vec_a = torch.tensor([[1.0, 0.0], [0.5, 0.5]], dtype=torch.float32)\n",
    "        self.vec_b = torch.tensor([[1.0, 0.0], [0.0, 1.0], [0.5, 0.5]], dtype=torch.float32)\n",
    "        \n",
    "    def assert_device(self, tensor, expected_device):\n",
    "        tensor_device = str(tensor.device)\n",
    "        expected_device = str(expected_device)\n",
    "        if expected_device == \"cuda\":\n",
    "            expected_device = \"cuda:0\"\n",
    "        assert tensor_device == expected_device, f\"Tensor is on {tensor_device}, expected {expected_device}\"\n",
    "    \n",
    "    def run_test(self, test_func, test_name):\n",
    "        try:\n",
    "            self.setup()\n",
    "            test_func()\n",
    "            self.results.append((test_name, \"✅ PASSED\", \"\"))\n",
    "        except Exception as e:\n",
    "            self.results.append((test_name, \"❌ FAILED\", str(e)))\n",
    "    \n",
    "    # 测试用例组\n",
    "    def test_device_control(self):\n",
    "        test_cases = [\n",
    "            (\"cpu\", \"cpu\"),\n",
    "            (\"auto\", \"auto\"),\n",
    "            (torch.device(\"cpu\"), \"cuda\"),\n",
    "            (\"cuda\", \"auto\"),\n",
    "        ]\n",
    "        \n",
    "        for work_dev, out_dev in test_cases:\n",
    "            if work_dev == \"cuda\" and not self.cuda_available:\n",
    "                continue\n",
    "            \n",
    "            result = embedding_similarity(self.vec_a, self.vec_b, \n",
    "                                        work_device=work_dev,\n",
    "                                        output_device=out_dev)\n",
    "            \n",
    "            expected_work = self.vec_a.device if work_dev == \"auto\" else torch.device(work_dev)\n",
    "            expected_out = expected_work if out_dev == \"auto\" else torch.device(out_dev)\n",
    "            \n",
    "            self.assert_device(result, expected_out)\n",
    "    \n",
    "    def test_calculation_accuracy(self):\n",
    "        test_cases = [\n",
    "            (cosine, [\n",
    "                [1.0, 0.0, 0.7071],\n",
    "                [0.7071, 0.7071, 1.0]\n",
    "            ]),\n",
    "            (tanimoto, [\n",
    "                [1.0, 0.0, 0.5],\n",
    "                [0.5, 0.5, 1.0]\n",
    "            ])\n",
    "        ]\n",
    "        \n",
    "        for sim_func, expected in test_cases:\n",
    "            result = embedding_similarity(self.vec_a, self.vec_b, sim_operator=sim_func)\n",
    "            np.testing.assert_allclose(result.numpy(), expected, atol=1e-4)\n",
    "    \n",
    "    def test_chunk_handling(self):\n",
    "        full_result = embedding_similarity(self.vec_a, self.vec_b, chunk_size=1024)\n",
    "        chunk_result = embedding_similarity(self.vec_a, self.vec_b, chunk_size=1)\n",
    "        assert torch.allclose(full_result, chunk_result), \"分块处理结果不一致\"\n",
    "    \n",
    "    def test_device_transfer(self):\n",
    "        if not self.cuda_available:\n",
    "            return\n",
    "        \n",
    "        # CPU计算，GPU输出\n",
    "        cpu_result = embedding_similarity(self.vec_a, self.vec_b, \n",
    "                                        work_device=\"cpu\",\n",
    "                                        output_device=\"cuda\")\n",
    "        self.assert_device(cpu_result, \"cuda:0\")\n",
    "        \n",
    "        # GPU计算，CPU输出\n",
    "        gpu_result = embedding_similarity(self.vec_a.to(\"cuda\"), self.vec_b,\n",
    "                                        output_device=\"cpu\")\n",
    "        self.assert_device(gpu_result, \"cpu\")\n",
    "    \n",
    "    def test_invalid_device(self):\n",
    "        try:\n",
    "            embedding_similarity(torch.randn(2,2), torch.randn(3,2),\n",
    "                                work_device=\"invalid_device\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            embedding_similarity(torch.randn(2,2), torch.randn(3,2),\n",
    "                                output_device=123)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    \n",
    "    def test_edge_cases(self):\n",
    "        # 空输入测试\n",
    "        empty_vec = torch.empty(0, 2)\n",
    "        result = embedding_similarity(empty_vec, empty_vec)\n",
    "        assert result.shape == (0, 0)\n",
    "        \n",
    "        # 单元素测试\n",
    "        single_vec = torch.tensor([[1.0, 0.0]])\n",
    "        result = embedding_similarity(single_vec, single_vec)\n",
    "        assert torch.allclose(result, torch.ones(1, 1))\n",
    "    \n",
    "    def show_results(self):\n",
    "        display(Markdown(\"## 测试结果汇总\"))\n",
    "        for name, status, error in self.results:\n",
    "            display(Markdown(f\"- {name}: {status}\"))\n",
    "            if error:\n",
    "                display(Markdown(f\"  ```\\n  {error}\\n  ```\"))\n",
    "\n",
    "#%% 执行所有测试\n",
    "if __name__ == \"__main__\":\n",
    "    runner = TestRunner()\n",
    "    \n",
    "    test_cases = [\n",
    "        (\"设备控制测试\", runner.test_device_control),\n",
    "        (\"计算精度测试\", runner.test_calculation_accuracy),\n",
    "        (\"分块处理测试\", runner.test_chunk_handling),\n",
    "        (\"设备转移测试\", runner.test_device_transfer),\n",
    "        (\"边界情况测试\", runner.test_edge_cases),\n",
    "    ]\n",
    "    \n",
    "    for name, test_func in test_cases:\n",
    "        runner.run_test(test_func, name)\n",
    "    \n",
    "    runner.show_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
