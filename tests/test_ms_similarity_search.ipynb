{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95bba618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import dask\n",
    "import dask.bag as db\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import ms_entropy as me\n",
    "from typing import Tuple,Callable,Optional,Union,Literal,List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca235268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_entropy_similarity(\n",
    "    query_spec: torch.Tensor, # (n_peaks, 2)\n",
    "    ref_spec: torch.Tensor, # (n_peaks, 2)\n",
    "    **kwargs,\n",
    ") -> torch.Tensor: # zero-dimensional\n",
    "    sim = me.calculate_entropy_similarity(query_spec, ref_spec, **kwargs)\n",
    "    return torch.tensor(sim, device=query_spec.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def spec_similarity_search_cpu(\n",
    "    query: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    ref: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = ms_entropy_similarity,\n",
    "    top_k: Optional[int] = None,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cpu\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    "    dask_mode: Optional[Literal[\"threads\", \"processes\", \"single-threaded\"]] = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    output_device = output_device or work_device\n",
    "    top_k = top_k or len(ref)\n",
    "    \n",
    "    # 缓冲区模板\n",
    "    scores_template = torch.full((top_k,), -float('inf'), \n",
    "                                device=work_device, dtype=torch.float32)\n",
    "    indices_template = torch.full((top_k,), -1, \n",
    "                                device=work_device, dtype=torch.long)\n",
    "    \n",
    "    # 单query搜索闭包\n",
    "    def _search_single_query(q: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # 初始化缓冲区\n",
    "        scores_buf = scores_template.clone()\n",
    "        indices_buf = indices_template.clone()\n",
    "        current_count = 0  # 有效结果计数器\n",
    "        \n",
    "        q_tensor = q.to(work_device)\n",
    "        \n",
    "        for r_idx, r_spec in enumerate(ref):\n",
    "            score = sim_operator(q_tensor, r_spec.to(work_device))\n",
    "\n",
    "            # 阶段1：缓冲区未满时的快速写入\n",
    "            if current_count < top_k:\n",
    "                scores_buf[current_count] = score\n",
    "                indices_buf[current_count] = r_idx\n",
    "                current_count += 1\n",
    "\n",
    "            # 阶段2：缓冲区已满后的条件替换\n",
    "            else:\n",
    "                min_idx = torch.argmin(scores_buf)\n",
    "                if score > scores_buf[min_idx]:  # 只需比较当前最小值\n",
    "                    # 定点替换\n",
    "                    scores_buf[min_idx] = score\n",
    "                    indices_buf[min_idx] = r_idx\n",
    "        \n",
    "        # 后处理缓冲区 （排序）\n",
    "        valid_part = scores_buf[:current_count]\n",
    "        sorted_idx = torch.argsort(valid_part, descending=True)\n",
    "        scores_buf[:current_count] = valid_part[sorted_idx]\n",
    "        indices_buf[:current_count] = indices_buf[:current_count][sorted_idx]\n",
    "\n",
    "        return scores_buf.to(output_device), indices_buf.to(output_device)\n",
    "\n",
    "    # Dask并行处理\n",
    "    query_bag = db.from_sequence(query, npartitions=num_dask_workers)\n",
    "    query_bag = query_bag.map(_search_single_query)\n",
    "    results = query_bag.compute(scheduler=dask_mode,num_workers=num_dask_workers)\n",
    "    \n",
    "    # 堆叠结果\n",
    "    results = pd.DataFrame(results,columns=[\"scores\", \"indices\"])\n",
    "    scores = torch.stack(results['scores'].tolist())\n",
    "    indices = torch.stack(results['indices'].tolist())\n",
    "    \n",
    "    return scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310be45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "        torch.tensor([[100.0, 1.0], [200.0, 0.8], [300.0, 0.5]], dtype=torch.float32),\n",
    "        torch.tensor([[150.0, 0.9], [250.0, 0.7], [350.0, 0.6]], dtype=torch.float32),\n",
    "        torch.tensor([[150.0, 0.9], [200.0, 0.7], [300.0, 0.6]], dtype=torch.float32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773608b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 103.01 ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    S,I = spec_similarity_search_cpu(queries, queries, top_k=2, num_dask_workers=2, dask_mode='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe6560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6201],\n",
       "        [1.0000, 0.3722],\n",
       "        [1.0000, 0.6201]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39dce39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [1, 2],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a7b8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def spec_similarity_search_cpu_by_queue(\n",
    "    query: List[List[torch.Tensor]],  # Queue[List[(n_peaks, 2)]]\n",
    "    ref: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = ms_entropy_similarity,\n",
    "    top_k: Optional[int] = None,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cpu\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    "    dask_mode: Optional[Literal[\"threads\", \"processes\", \"single-threaded\"]] = None,\n",
    ") -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "\n",
    "    output_device = output_device or work_device\n",
    "    top_k = top_k or len(ref)\n",
    "    \n",
    "    # 缓冲区模板\n",
    "    scores_template = torch.full((top_k,), -float('inf'), \n",
    "                                device=work_device, dtype=torch.float32)\n",
    "    indices_template = torch.full((top_k,), -1, \n",
    "                                device=work_device, dtype=torch.long)\n",
    "    \n",
    "    # 单query搜索闭包\n",
    "    def _search_single_query(i: int, q: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # 初始化缓冲区\n",
    "        scores_buf = scores_template.clone()\n",
    "        indices_buf = indices_template.clone()\n",
    "        current_count = 0  # 有效结果计数器\n",
    "        \n",
    "        q_tensor = q.to(work_device)\n",
    "        \n",
    "        for r_idx, r_spec in enumerate(ref[i]):\n",
    "            score = sim_operator(q_tensor, r_spec.to(work_device))\n",
    "\n",
    "            # 阶段1：缓冲区未满时的快速写入\n",
    "            if current_count < top_k:\n",
    "                scores_buf[current_count] = score\n",
    "                indices_buf[current_count] = r_idx\n",
    "                current_count += 1\n",
    "\n",
    "            # 阶段2：缓冲区已满后的条件替换\n",
    "            else:\n",
    "                min_idx = torch.argmin(scores_buf)\n",
    "                if score > scores_buf[min_idx]:  # 只需比较当前最小值\n",
    "                    # 定点替换\n",
    "                    scores_buf[min_idx] = score\n",
    "                    indices_buf[min_idx] = r_idx\n",
    "        \n",
    "        # 后处理缓冲区 （排序）\n",
    "        valid_part = scores_buf[:current_count]\n",
    "        sorted_idx = torch.argsort(valid_part, descending=True)\n",
    "        scores_buf[:current_count] = valid_part[sorted_idx]\n",
    "        indices_buf[:current_count] = indices_buf[:current_count][sorted_idx]\n",
    "\n",
    "        return scores_buf.to(output_device), indices_buf.to(output_device)\n",
    "    \n",
    "    # 构建配对序列\n",
    "    bag_queue = []\n",
    "    for i,query_block in enumerate(query):\n",
    "        query_block_bag = db.from_sequence(zip([i]*len(query_block), query_block), npartitions=num_dask_workers)\n",
    "        results_bag = query_block_bag.map(lambda x: _search_single_query(x[0], x[1]))\n",
    "        bag_queue.append(results_bag)\n",
    "    \n",
    "    # 并行搜索\n",
    "    queue_results = dask.compute(bag_queue, scheduler=dask_mode, num_workers=num_dask_workers)[0]\n",
    "    \n",
    "    # 合并结果\n",
    "    queue_results_bag = db.from_sequence(queue_results, npartitions=num_dask_workers)\n",
    "    queue_results_bag = queue_results_bag.map(lambda x: pd.DataFrame(x,columns=[\"scores\", \"indices\"]))\n",
    "    queue_results_bag = queue_results_bag.map(lambda x: (torch.stack(x['scores'].tolist()),torch.stack(x['indices'].tolist())))\n",
    "    queue_results = queue_results_bag.compute(scheduler=dask_mode, num_workers=num_dask_workers)\n",
    "    \n",
    "    return queue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53093ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 200.92 us"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 101.70 ms\n",
      "[########################################] | 100% Completed | 101.73 ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    queue_results = spec_similarity_search_cpu_by_queue([queries]*2, [queries]*2, top_k=2, num_dask_workers=2, dask_mode='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10aec515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1.0000, 0.6201],\n",
       "          [1.0000, 0.3722],\n",
       "          [1.0000, 0.6201]]),\n",
       "  tensor([[0, 2],\n",
       "          [1, 2],\n",
       "          [2, 0]])),\n",
       " (tensor([[1.0000, 0.6201],\n",
       "          [1.0000, 0.3722],\n",
       "          [1.0000, 0.6201]]),\n",
       "  tensor([[0, 2],\n",
       "          [1, 2],\n",
       "          [2, 0]]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87272610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cuda_sim_operator(q: torch.Tensor, r: torch.Tensor) -> torch.Tensor:\n",
    "    # 这里可以替换为实际的CUDA相似度计算函数\n",
    "    return torch.sum(torch.abs(q - r))\n",
    "\n",
    "@torch.no_grad()\n",
    "def spec_similarity_search_cuda(\n",
    "    query: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    ref: List[torch.Tensor], # List[(n_peaks, 2)]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    top_k: Optional[int] = None,\n",
    "    num_cuda_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    output_device = output_device or work_device\n",
    "    top_k = top_k or len(ref)\n",
    "    \n",
    "    # 初始化CUDA流组（每个worker含3个流）\n",
    "    stream_groups = [(\n",
    "        torch.cuda.Stream(device=work_device),  # 数据转移流\n",
    "        torch.cuda.Stream(device=work_device),  # 计算流\n",
    "        torch.cuda.Stream(device=work_device)    # 缓冲区流\n",
    "    ) for _ in range(num_cuda_workers)]\n",
    "\n",
    "    # 预分配显存资源\n",
    "    score_buffers = [torch.full((top_k,), -float('inf'), device=work_device) for _ in range(num_cuda_workers)]\n",
    "    index_buffers = [torch.full((top_k,), -1, device=work_device, dtype=torch.long) for _ in range(num_cuda_workers)]\n",
    "    event_pool = [torch.cuda.Event() for _ in range(num_cuda_workers*2)]\n",
    "\n",
    "    # 异步执行容器\n",
    "    results = [None] * len(query)\n",
    "    \n",
    "    for query_idx, q in enumerate(query):\n",
    "        worker_id = query_idx % num_cuda_workers\n",
    "        data_stream, compute_stream, buffer_stream = stream_groups[worker_id]\n",
    "        event_idx = worker_id * 2\n",
    "\n",
    "        # 阶段1: 异步数据传输\n",
    "        with torch.cuda.stream(data_stream):\n",
    "            q_gpu = q.to(work_device, non_blocking=True)\n",
    "            ref_gpu = [r.to(work_device, non_blocking=True) for r in ref]\n",
    "            event_pool[event_idx].record(stream=data_stream)\n",
    "\n",
    "        # 阶段2: 异步计算\n",
    "        with torch.cuda.stream(compute_stream):\n",
    "            event_pool[event_idx].wait(stream=compute_stream)  # 等待数据就绪\n",
    "            scores = []\n",
    "            for r_idx, r in enumerate(ref_gpu):\n",
    "                scores.append(sim_operator(q_gpu, r))\n",
    "            event_pool[event_idx+1].record(stream=compute_stream)\n",
    "\n",
    "        # 阶段3: 异步缓冲区更新\n",
    "        with torch.cuda.stream(buffer_stream):\n",
    "            event_pool[event_idx+1].wait(stream=buffer_stream)  # 等待计算完成\n",
    "            current_count = 0\n",
    "            score_buf = score_buffers[worker_id].zero_()\n",
    "            index_buf = index_buffers[worker_id].zero_()\n",
    "            \n",
    "            for r_idx, score in enumerate(scores):\n",
    "                if current_count < top_k:\n",
    "                    score_buf[current_count] = score\n",
    "                    index_buf[current_count] = r_idx\n",
    "                    current_count += 1\n",
    "                else:\n",
    "                    min_idx = torch.argmin(score_buf)\n",
    "                    if score > score_buf[min_idx]:\n",
    "                        score_buf[min_idx] = score\n",
    "                        index_buf[min_idx] = r_idx\n",
    "            \n",
    "            # 异步排序\n",
    "            sorted_idx = torch.argsort(score_buf[:current_count], descending=True)\n",
    "            score_buf[:current_count] = score_buf[:current_count][sorted_idx]\n",
    "            index_buf[:current_count] = index_buf[:current_count][sorted_idx]\n",
    "\n",
    "            # 异步传回结果\n",
    "            results[query_idx] = (\n",
    "                score_buf.to(output_device, non_blocking=True),\n",
    "                index_buf.to(output_device, non_blocking=True)\n",
    "            )\n",
    "\n",
    "    # 同步所有流\n",
    "    torch.cuda.synchronize(work_device)\n",
    "    \n",
    "    # 组装最终结果\n",
    "    return torch.stack([r[0] for r in results]), torch.stack([r[1] for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764e6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    results = spec_similarity_search_cuda(queries, queries, test_cuda_sim_operator, top_k=2, num_cuda_workers=2,output_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549bb48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[150.3000,  50.3000],\n",
       "         [150.3000, 100.0000],\n",
       "         [100.0000,  50.3000]]),\n",
       " tensor([[1, 2],\n",
       "         [0, 2],\n",
       "         [1, 0]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53ee318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def spec_similarity_search_cuda_by_queue(\n",
    "    query: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    ref: List[List[torch.Tensor]], # Queue[List[(n_peaks, 2)]]\n",
    "    sim_operator: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    top_k: Optional[int] = None,\n",
    "    num_cuda_workers: int = 4,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: torch.device = torch.device(\"cuda:0\"),\n",
    "    output_device: Optional[torch.device] = None,\n",
    ") -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "\n",
    "    block_bag = db.from_sequence(zip(query, ref), npartitions=num_dask_workers)\n",
    "    block_bag = block_bag.map(lambda x: spec_similarity_search_cuda(\n",
    "        x[0], x[1], sim_operator, top_k, num_cuda_workers, work_device, output_device\n",
    "    ))\n",
    "    results = block_bag.compute(scheduler='threads', num_workers=num_dask_workers)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "753c293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 220.48 us"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 102.10 ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    queue_results = spec_similarity_search_cuda_by_queue([queries]*2, [queries]*2, test_cuda_sim_operator, top_k=2, num_cuda_workers=2, num_dask_workers=2,output_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c476c197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[150.3000,  50.3000],\n",
       "          [150.3000, 100.0000],\n",
       "          [100.0000,  50.3000]]),\n",
       "  tensor([[1, 2],\n",
       "          [0, 2],\n",
       "          [1, 0]])),\n",
       " (tensor([[150.3000,  50.3000],\n",
       "          [150.3000, 100.0000],\n",
       "          [100.0000,  50.3000]]),\n",
       "  tensor([[1, 2],\n",
       "          [0, 2],\n",
       "          [1, 0]]))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2114cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "import torch\n",
    "from functools import partial\n",
    "from typing import Callable, Optional\n",
    "\n",
    "class EmbbedingSimilarityOperator(ABC):\n",
    "    \n",
    "    cpu_kwargs = {}\n",
    "    cuda_kwargs = {}\n",
    "    \n",
    "    @classmethod\n",
    "    def cuda_operator(\n",
    "        cls,\n",
    "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        '''\n",
    "        Returns a function that computes the similarity between two batches of embeddings.\n",
    "        The function takes two batches of embeddings and returns a similarity matrix.\n",
    "        The similarity matrix is a tensor of shape (batch_size_va, batch_size_vb) where each element (i, j)\n",
    "        represents the similarity between the i-th embedding in the first batch and the j-th embedding\n",
    "        in the second batch.\n",
    "        The function should be able to handle batches of different sizes.\n",
    "        '''\n",
    "        raise NotImplementedError(f\"{cls.__name__}.cuda_operator() not implemented\")\n",
    "    \n",
    "    @classmethod\n",
    "    def cpu_operator(\n",
    "        cls,\n",
    "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        '''\n",
    "        Returns a function that computes the similarity between two batches of embeddings.\n",
    "        The function takes two batches of embeddings and returns a similarity matrix.\n",
    "        The similarity matrix is a tensor of shape (batch_size_va, batch_size_vb) where each element (i, j)\n",
    "        represents the similarity between the i-th embedding in the first batch and the j-th embedding\n",
    "        in the second batch.\n",
    "        The function should be able to handle batches of different sizes.\n",
    "        '''\n",
    "        raise NotImplementedError(f\"{cls.__name__}.cpu_operator() not implemented\")\n",
    "    \n",
    "    @classmethod\n",
    "    def get_operator_kwargs(\n",
    "        cls,\n",
    "        device: torch.device,\n",
    "        input_kwargs: Optional[dict] = None,\n",
    "    ) -> dict:\n",
    "        if device.type.startswith(\"cuda\"):\n",
    "            return {**cls.cuda_kwargs, **(input_kwargs or {})}\n",
    "        else:\n",
    "            return {**cls.cpu_kwargs, **(input_kwargs or {})}\n",
    "        \n",
    "    @classmethod\n",
    "    def get_operator(\n",
    "        cls, \n",
    "        device: torch.device,\n",
    "        input_kwargs: Optional[dict] = None,\n",
    "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        if device.type.startswith(\"cuda\"):\n",
    "            return partial(cls.cuda_operator(), **cls.get_operator_kwargs(device,input_kwargs))\n",
    "        else:\n",
    "            return partial(cls.cpu_operator(), **cls.get_operator_kwargs(device,input_kwargs))\n",
    "        \n",
    "class SpectramSimilarityOperator(EmbbedingSimilarityOperator):\n",
    "    \n",
    "    dask_mode = None\n",
    "    \n",
    "    @classmethod\n",
    "    def cuda_operator(\n",
    "        cls,\n",
    "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        '''\n",
    "        Returns a function that computes the similarity between two spectra.\n",
    "        The function takes two batches of spectra and returns a similarity matrix.\n",
    "        The similarity matrix is a zero-dimensional tensor\n",
    "        '''\n",
    "        raise NotImplementedError(f\"{cls.__name__}.cuda_operator() not implemented\")\n",
    "    \n",
    "    @classmethod\n",
    "    def cpu_operator(\n",
    "        cls,\n",
    "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        '''\n",
    "        Returns a function that computes the similarity between two spectra.\n",
    "        The function takes two batches of spectra and returns a similarity matrix.\n",
    "        The similarity matrix is a zero-dimensional tensor\n",
    "        '''\n",
    "        raise NotImplementedError(f\"{cls.__name__}.cpu_operator() not implemented\")\n",
    "    \n",
    "    @classmethod\n",
    "    def get_dask_mode(\n",
    "        cls,\n",
    "        input_dask_mode: Optional[str] = None,\n",
    "    ) -> Optional[str]:\n",
    "        if input_dask_mode is not None:\n",
    "            return input_dask_mode\n",
    "        else:\n",
    "            return cls.dask_mode\n",
    "\n",
    "def resolve_device(\n",
    "    device: Union[str, torch.device, Literal['auto']], \n",
    "    default: torch.device\n",
    ") -> torch.device:\n",
    "    if isinstance(device, torch.device):\n",
    "        return device\n",
    "    if device == 'auto':\n",
    "        return default\n",
    "    if device == 'cuda':\n",
    "        device = 'cuda:0'\n",
    "    return torch.device(device)\n",
    "\n",
    "class MSEntropyOperator(SpectramSimilarityOperator):\n",
    "    \n",
    "    cpu_kwargs = {\n",
    "        \"ms2_tolerance_in_da\":0.02, \n",
    "        \"ms2_tolerance_in_ppm\": -1, \n",
    "        \"clean_spectra\": True,\n",
    "    }\n",
    "    dask_mode = \"threads\" # me.calculate_entropy_similarity是CPU函数，因此默认使用线程池\n",
    "    \n",
    "    @classmethod\n",
    "    def cpu_operator(cls):\n",
    "        return ms_entropy_similarity\n",
    "    \n",
    "    @classmethod\n",
    "    def cuda_operator(cls):\n",
    "        raise NotImplementedError(f\"{cls.__name__} not supported on CUDA\")\n",
    "\n",
    "def spec_similarity_search(\n",
    "    query: List[torch.Tensor],\n",
    "    ref: List[torch.Tensor],\n",
    "    sim_operator: SpectramSimilarityOperator = MSEntropyOperator,\n",
    "    top_k: Optional[int] = None,\n",
    "    num_cuda_workers: int = 4,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    output_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    dask_mode: Optional[Literal[\"threads\", \"processes\", \"single-threaded\"]] = None,\n",
    "    operator_kwargs: Optional[dict] = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    # 设备推断\n",
    "    _work_device = resolve_device(work_device, query[0].device if query else torch.device('cpu'))\n",
    "    _output_device = resolve_device(output_device, _work_device)\n",
    "    \n",
    "    # 算子生成\n",
    "    operator = sim_operator.get_operator(_work_device,operator_kwargs)\n",
    "\n",
    "    # 分发实现\n",
    "    if _work_device.type.startswith('cuda'):\n",
    "        return spec_similarity_search_cuda(\n",
    "            query, ref, operator,\n",
    "            top_k=top_k,\n",
    "            num_cuda_workers=num_cuda_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )\n",
    "    else:\n",
    "        return spec_similarity_search_cpu(\n",
    "            query, ref, operator,\n",
    "            top_k=top_k,\n",
    "            num_dask_workers=num_dask_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device,\n",
    "            dask_mode=sim_operator.get_dask_mode(dask_mode)\n",
    "        )\n",
    "\n",
    "def spec_similarity_search_by_queue(\n",
    "    query: List[List[torch.Tensor]],\n",
    "    ref: List[List[torch.Tensor]],\n",
    "    sim_operator: SpectramSimilarityOperator = MSEntropyOperator,\n",
    "    top_k: Optional[int] = None,\n",
    "    num_cuda_workers: int = 4,\n",
    "    num_dask_workers: int = 4,\n",
    "    work_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    output_device: Union[str, torch.device, Literal['auto']] = 'auto',\n",
    "    dask_mode: Optional[Literal[\"threads\", \"processes\", \"single-threaded\"]] = None,\n",
    "    operator_kwargs: Optional[dict] = None,\n",
    ") -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \n",
    "    # 设备推断\n",
    "    _work_device = resolve_device(work_device, query[0][0].device if query else torch.device('cpu'))\n",
    "    _output_device = resolve_device(output_device, _work_device)\n",
    "    \n",
    "    # 算子生成\n",
    "    operator = sim_operator.get_operator(_work_device,operator_kwargs)\n",
    "    \n",
    "    # 分发实现\n",
    "    if _work_device.type.startswith('cuda'):\n",
    "        return spec_similarity_search_cuda_by_queue(\n",
    "            query, ref, operator,\n",
    "            top_k=top_k,\n",
    "            num_cuda_workers=num_cuda_workers,\n",
    "            num_dask_workers=num_dask_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device\n",
    "        )\n",
    "    else:\n",
    "        return spec_similarity_search_cpu_by_queue(\n",
    "            query, ref, operator,\n",
    "            top_k=top_k,\n",
    "            num_dask_workers=num_dask_workers,\n",
    "            work_device=_work_device,\n",
    "            output_device=_output_device,\n",
    "            dask_mode=sim_operator.get_dask_mode(dask_mode)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e286cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_work_device = resolve_device(\"auto\", queries[0][0].device if queries else torch.device('cpu'))\n",
    "_output_device = resolve_device(\"auto\", _work_device)\n",
    "operator = MSEntropyOperator.get_operator(_work_device,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d34f4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 442.39 us"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 102.83 ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    results = spec_similarity_search(\n",
    "        queries,queries\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c3d615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.6201, 0.0000],\n",
       "         [1.0000, 0.3722, 0.0000],\n",
       "         [1.0000, 0.6201, 0.3722]]),\n",
       " tensor([[0, 2, 1],\n",
       "         [1, 2, 0],\n",
       "         [2, 0, 1]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9ab54bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 209.20 us"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 102.14 ms\n",
      "[########################################] | 100% Completed | 102.05 ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    results = spec_similarity_search_by_queue(\n",
    "        [queries]*2,[queries]*2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "745ff6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1.0000, 0.6201],\n",
       "          [1.0000, 0.3722],\n",
       "          [1.0000, 0.6201]]),\n",
       "  tensor([[0, 2],\n",
       "          [1, 2],\n",
       "          [2, 0]])),\n",
       " (tensor([[1.0000, 0.6201],\n",
       "          [1.0000, 0.3722],\n",
       "          [1.0000, 0.6201]]),\n",
       "  tensor([[0, 2],\n",
       "          [1, 2],\n",
       "          [2, 0]]))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
